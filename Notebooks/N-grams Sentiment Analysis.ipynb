{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import re as re\n",
    "import zipfile as zipfile\n",
    "import string\n",
    "from collections import defaultdict, Counter\n",
    "mytextzip = ''\n",
    "corpus = []\n",
    "labels = []\n",
    "def readfromzip(zipname: str, n_docs: int) -> None:\n",
    "    global mytextzip\n",
    "    global c\n",
    "    with zipfile.ZipFile(zipname) as z:\n",
    "        for zipinfo in z.infolist():\n",
    "            if zipinfo.filename.endswith('.txt') and re.search('raw_texts', zipinfo.filename):\n",
    "                with z.open(zipinfo) as f:\n",
    "                    textfile = io.TextIOWrapper(f, encoding='cp1254', newline='\\r\\n')\n",
    "                    for line in textfile:\n",
    "                        if len(line):\n",
    "                            if re.search(r'([a-zA-Z]+\\r\\n)', line):\n",
    "                                mytextzip += line.strip() + ' '\n",
    "                                continue\n",
    "                            mytextzip += line.strip()\n",
    "                    corpus.append(mytextzip)\n",
    "                    labels.append(zipinfo.filename.split(\"/\")[2])\n",
    "                    if len(corpus) >= n_docs:\n",
    "                        break\n",
    "                    mytextzip =''\n",
    "readfromzip('film_yorumlari.zip',1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(len(corpus)):\n",
    "    corpus[t] = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', corpus[t].lower())\n",
    "    for i in range(len(corpus[t])):\n",
    "        corpus[t][i] = \"<SOS> \" + corpus[t][i] + \" <EOS>\"\n",
    "    corpus[t] = ' '.join(corpus[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def split(X, y, test_size, set_seed):\n",
    "    arrays = [X,y]\n",
    "    assert all(len(arr) == len(arrays[0]) for arr in arrays)\n",
    "    seed = np.random.randint(0, 2**(32 - 1) - 1) if set_seed < 0 else set_seed\n",
    "    \n",
    "    for arr in arrays:\n",
    "        rstate = np.random.RandomState(seed)\n",
    "        rstate.shuffle(arr)\n",
    "        \n",
    "    size = int(len(X)*test_size)\n",
    "    x_train, x_test = X[size:], X[:size]\n",
    "    y_train, y_test = y[size:], y[:size]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(corpus, labels, 0.2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_runtime_complexity = O(len(corpus)*(len(text)-4)*n)\n",
    "import math, sys\n",
    "class Ngrams():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        \n",
    "    \n",
    "    def _train(self, corpus, labels):\n",
    "        awd = defaultdict(lambda: defaultdict(int))\n",
    "        ngrams = defaultdict(lambda: defaultdict(list))\n",
    "        self.labels = labels\n",
    "        for i, text in enumerate(corpus):\n",
    "            label = self.labels[i]\n",
    "            text = text.split()\n",
    "            for i in range(len(text)-self.n+1):\n",
    "                before = ' '.join([text[i+j] for j in range(self.n-1)])\n",
    "                awd[label][before] += 1\n",
    "                ngrams[label][before].append(text[i+self.n-1])\n",
    "            pre = ' '.join([text[-i] for i in range(1, self.n)])\n",
    "            awd[label][pre] += 1\n",
    "        for a in ngrams.keys():\n",
    "            for k in ngrams[a].keys():\n",
    "                ngrams[a][k] = Counter(ngrams[a][k])\n",
    "                ngrams[a][k] = (awd[a][k], ngrams[a][k])\n",
    "        return ngrams\n",
    "    \n",
    "    def train(self, corpus, labels):\n",
    "        self.ngrams = self._train(corpus, labels)\n",
    "                \n",
    "    def _predict(self, text):\n",
    "        prob = -sys.maxsize\n",
    "        res = None\n",
    "        text = text.split()\n",
    "        for label in set(self.labels):\n",
    "            newprob = 0\n",
    "            for i in range(len(text)-1):\n",
    "                try:\n",
    "                    before = ' '.join([text[i+j] for j in range(self.n-1)])\n",
    "                    totalC = self.ngrams[label][before][0]\n",
    "                    togetherC = self.ngrams[label][before][1][text[i+self.n-1]]\n",
    "                    ans = togetherC / totalC\n",
    "                    newprob += math.log(ans)\n",
    "                except:\n",
    "                    newprob += math.log(1e-10)\n",
    "            if newprob > prob:\n",
    "                prob = newprob\n",
    "                res = label\n",
    "        return res\n",
    "        \n",
    "    def predict(self, corpus):\n",
    "        self.preds = []\n",
    "        for t in range(len(corpus)):\n",
    "            self.preds.append(self._predict(corpus[t]))\n",
    "        return self.preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = Ngrams(2)\n",
    "ng.train(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ng.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    acc = 0\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            acc += 1\n",
    "    print(str(acc) + \"/\" + str(len(y_test)))\n",
    "    return (acc*100)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.61904761904762"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
